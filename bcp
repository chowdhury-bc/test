import boto3
import json
import uuid
import time

class MCPDemo:
    def __init__(self, model_id="anthropic.claude-3-sonnet-20240229-v1:0"):
        """Initialize the MCP Demo with the specified model."""
        self.bedrock_runtime = boto3.client('bedrock-runtime')
        self.model_id = model_id
        self.conversations = {}  # Store conversation histories

    def create_conversation(self, system_prompt=None):
        """Create a new conversation with an optional system prompt."""
        conversation_id = str(uuid.uuid4())
        self.conversations[conversation_id] = {
            "messages": [],
            "system_prompt": system_prompt or "You are a helpful assistant."
        }
        return conversation_id

    def add_message(self, conversation_id, role, content):
        """Add a message to an existing conversation."""
        if conversation_id not in self.conversations:
            raise ValueError(f"Conversation {conversation_id} does not exist.")
        
        self.conversations[conversation_id]["messages"].append({
            "role": role,
            "content": content
        })

    def generate_response(self, conversation_id):
        """Generate a response from the model based on conversation history."""
        if conversation_id not in self.conversations:
            raise ValueError(f"Conversation {conversation_id} does not exist.")
        
        conversation = self.conversations[conversation_id]
        
        # Format the request according to Bedrock's Claude API
        request_body = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 1000,
            "system": conversation["system_prompt"],
            "messages": conversation["messages"]
        }
        
        # Invoke the model
        response = self.bedrock_runtime.invoke_model(
            modelId=self.model_id,
            body=json.dumps(request_body)
        )
        
        # Parse the response
        response_body = json.loads(response['body'].read().decode('utf-8'))
        
        # Add the assistant's response to the conversation history
        self.add_message(
            conversation_id,
            "assistant",
            response_body["content"][0]["text"]
        )
        
        return response_body["content"][0]["text"]

    def list_conversations(self):
        """List all conversation IDs."""
        return list(self.conversations.keys())

    def get_conversation_history(self, conversation_id):
        """Get the full history of a conversation."""
        if conversation_id not in self.conversations:
            raise ValueError(f"Conversation {conversation_id} does not exist.")
        
        return self.conversations[conversation_id]["messages"]


def run_demo():
    """Run a simple interactive demo of the MCP system."""
    print("Starting MCP Demo with AWS Bedrock")
    mcp = MCPDemo()
    
    # Create two separate conversations
    conv1_id = mcp.create_conversation("You are a helpful AI assistant focused on technology.")
    conv2_id = mcp.create_conversation("You are a creative writing assistant who speaks like Shakespeare.")
    
    print(f"Created two conversations: {conv1_id} (Tech) and {conv2_id} (Shakespeare)")
    
    # Demonstrate conversation 1 (Tech)
    print("\n--- Tech Conversation ---")
    tech_query = "What are the main benefits of serverless architecture?"
    print(f"User: {tech_query}")
    
    mcp.add_message(conv1_id, "user", tech_query)
    response = mcp.generate_response(conv1_id)
    
    print(f"Assistant: {response[:200]}...\n")
    
    # Demonstrate conversation 2 (Shakespeare)
    print("\n--- Shakespeare Conversation ---")
    shakespeare_query = "Tell me about cloud computing."
    print(f"User: {shakespeare_query}")
    
    mcp.add_message(conv2_id, "user", shakespeare_query)
    response = mcp.generate_response(conv2_id)
    
    print(f"Assistant: {response[:200]}...\n")
    
    # Continue conversation 1 with follow-up
    print("\n--- Tech Conversation (continued) ---")
    tech_followup = "How does it compare to container-based solutions?"
    print(f"User: {tech_followup}")
    
    mcp.add_message(conv1_id, "user", tech_followup)
    response = mcp.generate_response(conv1_id)
    
    print(f"Assistant: {response[:200]}...\n")
    
    # Show the conversation histories
    print("\n--- Conversation Histories ---")
    
    print("\nTech Conversation History:")
    for msg in mcp.get_conversation_history(conv1_id):
        print(f"{msg['role'].capitalize()}: {msg['content'][:100]}...")
    
    print("\nShakespeare Conversation History:")
    for msg in mcp.get_conversation_history(conv2_id):
        print(f"{msg['role'].capitalize()}: {msg['content'][:100]}...")


if __name__ == "__main__":
    run_demo()
